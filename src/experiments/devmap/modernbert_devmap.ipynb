{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cf6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import yaml\n",
    "from transformers import (\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    logging as hf_logging\n",
    ")\n",
    "from datasets import load_from_disk\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc595d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# 设置模型路径\n",
    "model_path = \"/home/xucong24/Compiler/work_dirs/modernbert_poj104_mlm_train/20250923_141929/final_model\"\n",
    "\n",
    "# 加载模型和分词器\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b013ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Using device: cuda\n",
      "n_params=1.4901e+08\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "modernbert = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "modernbert = modernbert.model\n",
    "modernbert = modernbert.to(device)\n",
    "n_params = sum(p.numel() for p in modernbert.parameters())\n",
    "print(f\"{n_params=:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973f5349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModernBertModel(\n",
       "  (embeddings): ModernBertEmbeddings(\n",
       "    (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): ModernBertEncoderLayer(\n",
       "      (attn_norm): Identity()\n",
       "      (attn): ModernBertAttention(\n",
       "        (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (rotary_emb): ModernBertRotaryEmbedding()\n",
       "        (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_drop): Identity()\n",
       "      )\n",
       "      (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): ModernBertMLP(\n",
       "        (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (act): GELUActivation()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1-21): 21 x ModernBertEncoderLayer(\n",
       "      (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): ModernBertAttention(\n",
       "        (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (rotary_emb): ModernBertRotaryEmbedding()\n",
       "        (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_drop): Identity()\n",
       "      )\n",
       "      (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): ModernBertMLP(\n",
       "        (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (act): GELUActivation()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modernbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d9876c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50281,    28, 30073,  1838,   426, 17882,  8658,  1506,    16, 22559,\n",
       "         15453,    16,  2437,  1419,  1212,    64,  3211,    16,  2566,    16,\n",
       "          2691,    16,  1797,    15, 10134,    15, 14161,     8,   187,  7831,\n",
       "          2856,   267,  5038,   426,   346,    70,    14,    78,    27,    70,\n",
       "            14,    74,  1540,    27,  1540,    14,    71,  1438,    27,  8196,\n",
       "            14,    79,    25,    27,  1036,    27,  1237,    27,  1540,    14,\n",
       "            52,  8196,     3,   187,  7831, 16260,   426,   346,    89,  2691,\n",
       "            64,  1540,    14, 29469,    14, 13217,    14, 26497,     3,   187,\n",
       "           187, 28764,  2437,    15,  8400,  1450,  3783,    64,  4793,  1450,\n",
       "         10828,     3,   426,  1511,   551,   891,    25,   748,   187,   187,\n",
       "            33,    64,    59,   998,    45,    25,   876,   900,  4478,   426,\n",
       "          4812,  4156,  2462,     3,  2437,    15,  8400,  1450,  3783,    64,\n",
       "          4793,  1450, 10828,     3,  5058, 19078,  6081,    13,  8495,   337,\n",
       "           187,    33,   876,    69,   601,    64, 13393,   426,  6024,  4156,\n",
       "           891,    25,   187,    33,    15,  1344,   426,  3055, 42540,    64,\n",
       "          9834,  3638,   544,    20,  1269,   891,    25,    62,   260,     3,\n",
       "             6,    69,    61,   361,   995,  8495,   337,   187,    33,    15,\n",
       "          1344,    15,    18,   426,  3055, 42540,    64,  9834,  3638,   544,\n",
       "            21,  1269,   891,    25,    62,   260,     3,     6,    69,    61,\n",
       "            17,    34,    61,   361,   995,  8495,   337,   187,    33, 38381,\n",
       "            15, 14456,    64,  5285,   426,   622,  1946,  4156,   544,    18,\n",
       "          1269,   551,   891,  1237,    13,  2991,   313,  2888,    13,   891,\n",
       "            25,    11,   748,    62, 33440,   891,  1237,    13,  2991,   313,\n",
       "          2888,    13,   891,    25,    11,   748,   551,   891,  1237, 39005,\n",
       "          1671,    13,  2991,   313,  2888,  1214,    64, 48430,  1556,   876,\n",
       "          2377,    64,    42,    64,  1797,    15, 10134,    15, 14161,    13,\n",
       "           891,    25,    11,  3635,   748,    62,   187,   187,  3182,  4812,\n",
       "          2991,  1214,   876,    68,  5260,    64, 14456,    64,  2044,    64,\n",
       "          4478,  1082,  1852,    17,  2593, 22746,  1156,    15,  5478,   484,\n",
       "             3,   551,   187,  8873,    27,   187, 50276,  4065,  2991,  1214,\n",
       "            64,    59,    47,   998,    25,  3783,    64,  4793,    21, 10828,\n",
       "            36,    18, 12018, 24722,     3,  2437,    15,  8400,  1450,  3783,\n",
       "            64,  4793,  1450, 10828,     3,    11,  1214,    64,    59,   998,\n",
       "            45,    25,   876,   900,  4478,    10,   187, 50276,     6,    17,\n",
       "           426,  1067,   891,  1237,  1214,   876,    68, 14346,    64,   366,\n",
       "         19706,     9,  4353,   313,    74,    25,    11,  2888,  2372,  4008,\n",
       "           313,  4353, 26607,     3,  2437,    15,  8400,  1450,  3783,    64,\n",
       "          4793,  1450, 10828,     3,    11,  2888,  1214,    64,    59,    47,\n",
       "           998,    25,  3783,    64,  4793,    21, 10828,    37,    18, 12018,\n",
       "           281,  2991,   313,    74,    25,    11,  2888,   582,   891,    25,\n",
       "            11,   755, 10531,  4773,   275, 35800, 26607,     3,  2437,    15,\n",
       "          8400,  1450,  3783,    64,  4793,  1450, 10828,   995,  2462,     3,\n",
       "          2437,    15,  8400,  1450,  3783,    64,  4793,  1450, 10828,     3,\n",
       "            11,  1214,    64,    59,   998,    45,    25,   876,   900,  4478,\n",
       "            13,   891,  1237,   470,    13,   891,  1237,   470,   582,   891,\n",
       "            25,    11,  1214,   876,    69,   601,    64, 13393,    10,  1852,\n",
       "            18,   187, 50276,  1221,  2991,   187,    94,   187,   187, 42754,\n",
       "          2991,  1214,    64,    59,    47,   998,    25,  3783,    64,  4793,\n",
       "            21, 10828,    36,    18, 12018, 24722,     3,  2437,    15,  8400,\n",
       "          1450,  3783,    64,  4793,  1450, 10828,     3,  5627,  1852,    17,\n",
       "           187,   187, 42754,  2991,  1214,    64,    59,    47,   998,    25,\n",
       "          3783, 50282]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/home/xucong24/Compiler/datasets/poj104/ir_test/86/21.ll\", \"r\") as f:\n",
    "    llvm = f.read()\n",
    "inputs = tokenizer([llvm], return_tensors=\"pt\", max_length=512, padding='max_length', truncation=True)  \n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d6f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备处理\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# 设置模型为评估模式\n",
    "modernbert.eval()\n",
    "\n",
    "# 正确的推理方式 - 使用 ** 解包字典\n",
    "with torch.no_grad():\n",
    "    outputs = modernbert(**inputs, output_hidden_states=True, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab39fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003260a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0203be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/xucong24/Compiler/datasets/devmap'\n",
    "platform = 'all'\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "dense_layer_size = 32\n",
    "print_summary = False\n",
    "out_folder = '/home/xucong24/Compiler/work_dirs/modernbert_for_devmap'\n",
    "num_classes = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "platform2str = {\n",
    "    \"amd\": \"AMD Tahiti 7970\",\n",
    "    \"nvidia\": \"NVIDIA GTX 970\"\n",
    "}\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "assert platform in ['all', 'amd', 'nvidia'], \\\n",
    "    'Choose device among: all, amd, nvidia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b8a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载DevMap数据\n",
    "def load_data(data_path, platform):\n",
    "    # Load runtime data\n",
    "    df = pd.read_csv(data_path + \"/cgo17-{}.csv\".format(platform), index_col=0)\n",
    "    print('--- Read data from', data_path)\n",
    "\n",
    "    df[\"bench_data\"] = (\n",
    "        df.loc[df[\"dataset\"] != \"default\", \"benchmark\"]\n",
    "        + str(\"_\")\n",
    "        + df.loc[df[\"dataset\"] != \"default\", \"dataset\"]\n",
    "    )\n",
    "    df.loc[df[\"dataset\"] == \"default\", \"bench_data\"] = df.loc[\n",
    "        df[\"dataset\"] == \"default\", \"benchmark\"\n",
    "    ]\n",
    "\n",
    "    # llvm文件路径\n",
    "    df[\"bench_data_path\"] = data_path + '/kernels_ir/' + df[\"bench_data\"] + str(\".ll\")\n",
    "\n",
    "    # inst2vec编码\n",
    "    input_files = df[\"bench_data_path\"].values  \n",
    "    num_files = len(input_files)\n",
    "    print('--- Preparing to read', num_files, 'input files from folder', data_path + '/kernels_ir/')\n",
    "    seqs = list()\n",
    "\n",
    "    # 遍历文件，读取ir\n",
    "    bad = []\n",
    "    for i in tqdm(range(num_files), desc='Encoding files'):\n",
    "        file = input_files[i]\n",
    "        if os.path.exists(file):\n",
    "            with open(file) as f:\n",
    "                ir = f.read()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 假设 data 是输入张量或字典\n",
    "                inputs = tokenizer([ir], return_tensors=\"pt\", max_length=512, padding='max_length', truncation=True)\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                outputs = modernbert(**inputs, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "                seqs.append(outputs[0].squeeze().to('cpu'))\n",
    "        else:\n",
    "            bad.append(i)\n",
    "    print(bad)\n",
    "            \n",
    "    # print('Number of benchmark  : {:>5}'.format(num_files))\n",
    "    # print('Mean sequence length : {:>5} (rounded down)'.format(math.floor(np.mean(seq_lengths))))\n",
    "    # print('Number of \\'UNK\\'      : {:>5}'.format(num_unks))\n",
    "    # print('Percentage of \\'UNK\\'  : {:>8.4} (% among all stmts)'.format((num_unks*100)/sum(seq_lengths)))\n",
    "\n",
    "    df = df.drop(bad)\n",
    "\n",
    "    # aux data\n",
    "    aux_in = np.array([\n",
    "        df[\"transfer\"].values,\n",
    "        df[\"wgsize\"].values,\n",
    "    ]).T\n",
    "    \n",
    "    # 标签\n",
    "    label = np.array([1 if x == \"GPU\" else 0 for x in df[\"oracle\"].values])\n",
    "\n",
    "    return seqs, aux_in, label, df\n",
    "    \n",
    "class DevMapDataset(Dataset):\n",
    "    def __init__(self, sequences, aux_in, y):\n",
    "        super().__init__()\n",
    "        self.sequences = sequences\n",
    "        self.aux_in = aux_in\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        seqs = self.sequences[index]\n",
    "        aux = self.aux_in[index]\n",
    "        label = self.y[index]\n",
    "        return seqs, aux, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bc9fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "class DevMapLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_layers, dropout):\n",
    "        super(DevMapLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, embedding_dim, num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim * 2, num_classes)\n",
    "        \n",
    "        # self.fc_with_aux = nn.Linear(embedding_dim * 2 + 2, num_classes)\n",
    "    \n",
    "        # self.language_model_out = nn.Linear(embedding_dim, 2)\n",
    "        self.batch_norm = nn.BatchNorm1d(embedding_dim * 2 + 2)\n",
    "        # self.dense_1 = nn.Linear(embedding_dim * 2 + 2, 128)\n",
    "        # self.output = nn.Linear(128, 2)\n",
    "        self.fc2 = nn.Linear(embedding_dim * 2 + 2, 2)\n",
    "        \n",
    "    def forward(self, x, aux_input):\n",
    "\n",
    "        # x = self.embedding(x)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        lang_output = self.fc(x[:, -1, :])\n",
    "        # final_output = self.fc_with_aux(torch.cat((aux_input, x[:, -1, :]), dim=1))\n",
    "        \n",
    "        # out, _ = self.lstm_1(x)\n",
    "        # out, _ = self.lstm_2(out)\n",
    "        # lang_output = torch.sigmoid(self.language_model_out(out[:, -1, :]))\n",
    "        x_combined = torch.cat((aux_input, x[:, -1, :]), dim=1)\n",
    "        x_combined = self.batch_norm(x_combined)\n",
    "        # x_combined = torch.relu(self.dense_1(x_combined))\n",
    "        # final_output = torch.sigmoid(self.output(x_combined))\n",
    "        final_output = self.fc2(x_combined)\n",
    "        return final_output, lang_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce9c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_suite_name(g: str) -> str:\n",
    "    c = g.split('-')\n",
    "    if c[0] == \"amd\" or c[0] == \"nvidia\":\n",
    "        return c[0].upper() + \" SDK\"\n",
    "    if c[0] == \"npb\" or c[0] == \"shoc\":\n",
    "        return c[0].upper()\n",
    "    elif c[0] == \"parboil\" or c[0] == \"polybench\" or c[0] == \"rodinia\":\n",
    "        return c[0].capitalize()\n",
    "    else:\n",
    "        raise LookupError\n",
    "\n",
    "def escape_benchmark_name(g: str) -> str:\n",
    "    c = g.split('-')\n",
    "    return escape_suite_name(c[0]).split()[0] + \".\" + c[-2]\n",
    "\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    pred_list, label_list =  [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, aux_input, labels = [b.to(device) for b in batch]\n",
    "            outputs, lang_outputs = model(sequences, aux_input)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            pred_list.extend(preds.tolist())\n",
    "            label_list.extend(batch[2].tolist())\n",
    "            \n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return accuracy, pred_list, label_list\n",
    "\n",
    "def train_model(model, train_loader, test_loader,  criterion, optimizer, num_epochs, model_path):\n",
    "    # 模型训练\n",
    "    pre_eval_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        model.train()\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "        for idx, batch in enumerate(progress_bar):\n",
    "            sequences, aux_input, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, lang_outputs = model(sequences, aux_input)\n",
    "\n",
    "            # 计算loss值 由output和lang_outputs与label计算CrossEntropyLoss\n",
    "            loss = criterion(outputs, labels) + 0.2 * criterion(lang_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            progress_bar.set_postfix(loss=epoch_loss / (idx + 1))\n",
    "                    \n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "        eval_acc,_ , _ = eval_model(model, test_loader)\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}, loss: {epoch_loss:.4f}, train_acc: {accuracy:.4f}, eval_acc: {eval_acc:.4f}\")\n",
    "\n",
    "        if eval_acc > pre_eval_acc:\n",
    "            pre_eval_acc = eval_acc\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, weights_only=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3898e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Read data from /home/xucong24/Compiler/datasets/devmap\n",
      "--- Preparing to read 680 input files from folder /home/xucong24/Compiler/datasets/devmap/kernels_ir/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding files: 100%|██████████| 680/680 [01:04<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555, 556, 557, 558, 559, 560, 561, 562, 564, 566, 568, 569, 570, 571, 573]\n",
      "--- Cross validation step [ 0 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-0.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8209\n",
      "--- Cross validation step [ 1 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-1.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8060\n",
      "--- Cross validation step [ 2 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-2.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7313\n",
      "--- Cross validation step [ 3 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-3.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6567\n",
      "--- Cross validation step [ 4 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-4.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6269\n",
      "--- Cross validation step [ 5 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-5.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7273\n",
      "--- Cross validation step [ 6 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-6.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6970\n",
      "--- Cross validation step [ 7 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-7.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7576\n",
      "--- Cross validation step [ 8 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-8.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6212\n",
      "--- Cross validation step [ 9 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-amd-9.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7727\n",
      "--- Read data from /home/xucong24/Compiler/datasets/devmap\n",
      "--- Preparing to read 680 input files from folder /home/xucong24/Compiler/datasets/devmap/kernels_ir/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding files: 100%|██████████| 680/680 [00:30<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555, 556, 557, 558, 559, 560, 561, 562, 564, 566, 568, 569, 570, 571, 573]\n",
      "--- Cross validation step [ 0 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-0.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6567\n",
      "--- Cross validation step [ 1 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-1.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6418\n",
      "--- Cross validation step [ 2 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-2.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6866\n",
      "--- Cross validation step [ 3 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-3.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6269\n",
      "--- Cross validation step [ 4 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-4.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7761\n",
      "--- Cross validation step [ 5 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-5.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6667\n",
      "--- Cross validation step [ 6 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-6.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7424\n",
      "--- Cross validation step [ 7 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-7.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7879\n",
      "--- Cross validation step [ 8 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-8.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6667\n",
      "--- Cross validation step [ 9 / 10 ]\n",
      "Found trained model in /home/xucong24/Compiler/work_dirs/modernbert_for_devmap/models/inst2vec_modern_bert_lstm-nvidia-9.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7273\n"
     ]
    }
   ],
   "source": [
    "# platform_list = [\"amd\", \"nvidia\"]\n",
    "platform_list = [\"amd\", \"nvidia\"]\n",
    "\n",
    "data = []\n",
    "for i, platform in enumerate(platform_list):\n",
    "    # 读取数据集\n",
    "    sequences, aux_in, y, df = load_data(data_folder, platform)\n",
    "    aux_in_tensor = torch.tensor(aux_in, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "    # 使用 F.normalize 进行 L2 归一化\n",
    "    # embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    # embedding_matrix_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=204)\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(sequences, y)):\n",
    "        print('--- Cross validation step [', j, '/ 10 ]')\n",
    "\n",
    "        model_basename = 'inst2vec_modern_bert_lstm'\n",
    "        model_path = os.path.join(out_folder, f\"models/{model_basename}-{platform}-{j}.pth\")\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        log_dir = os.path.join(out_folder, \"logs\")\n",
    "\n",
    "        # 读取数据集\n",
    "        train_data = DevMapDataset([sequences[i] for i in train_index], aux_in_tensor[train_index], y_tensor[train_index])\n",
    "        test_data = DevMapDataset([sequences[i] for i in test_index], aux_in_tensor[test_index], y_tensor[test_index])\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            # 创建模型\n",
    "            model = DevMapLSTM(768, 3, 0.5).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "            print('--- Training model... ')\n",
    "            train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, model_path)\n",
    "            \n",
    "        else:\n",
    "            # 读取模型权重文件\n",
    "            model = DevMapLSTM(768, 3, 0.5)\n",
    "            model.load_state_dict(torch.load(model_path, weights_only=False))\n",
    "            model = model.to(device)\n",
    "            print(\"Found trained model in\", model_path, \", skipping...\")\n",
    "            \n",
    "        # 模型预测\n",
    "        eval_acc, pred_list, label_list = eval_model(model, test_loader)\n",
    "        print(f'--- Evaluate Accuracy {eval_acc:.4f}')\n",
    "        benchmarks = df['benchmark'].values[test_index]\n",
    "        correct = np.array(pred_list) == np.array(label_list)\n",
    "        zero_r_dev = \"runtime_cpu\" if platform == \"amd\" else \"runtime_gpu\"\n",
    "        zer_r_runtimes = df[zero_r_dev].values[test_index]\n",
    "        runtimes = df[['runtime_cpu', 'runtime_gpu']].values[test_index]\n",
    "        p_runtimes = [r[p_] for p_, r in zip(np.array(pred_list, dtype=int), runtimes)]\n",
    "        p_speedup = zer_r_runtimes / p_runtimes\n",
    "\n",
    "        assert len(benchmarks) == len(label_list) == len(correct) == len(pred_list) == len(p_speedup)\n",
    "\n",
    "        for benchmark_, o_, p_, correct_, p_speedup_ in zip(benchmarks, label_list, pred_list, correct, p_speedup):\n",
    "            data.append({\n",
    "                \"Model\": model_basename,\n",
    "                \"Platform\": platform2str[platform],\n",
    "                'Benchmark': escape_benchmark_name(benchmark_),\n",
    "                'Benchmark Suite': escape_suite_name(benchmark_),\n",
    "                \"Oracle Mapping\": int(o_),\n",
    "                \"Predicted Mapping\": int(p_),\n",
    "                \"Correct?\": bool(correct_),\n",
    "                \"Speedup\": float(p_speedup_),\n",
    "            })\n",
    "            \n",
    "result =  pd.DataFrame(\n",
    "    data, index=range(1, len(data) + 1), columns=[\n",
    "        \"Model\",\n",
    "        \"Platform\",\n",
    "        \"Benchmark\",\n",
    "        \"Benchmark Suite\",\n",
    "        \"Oracle Mapping\",\n",
    "        \"Predicted Mapping\",\n",
    "        \"Correct?\",\n",
    "        \"Speedup\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c455e07d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction results\n",
      "                                 Correct?    Speedup\n",
      "Platform        Benchmark Suite                     \n",
      "AMD Tahiti 7970 AMD SDK          0.562500   0.913787\n",
      "                NPB              0.749526   2.958338\n",
      "                NVIDIA SDK       0.750000   3.394625\n",
      "                Parboil          0.750000   1.771634\n",
      "                Polybench        0.851852  13.750485\n",
      "                Rodinia          0.451613   3.748234\n",
      "                SHOC             0.562500   1.247279\n",
      "NVIDIA GTX 970  AMD SDK          0.250000   0.545483\n",
      "                NPB              0.721063   1.333634\n",
      "                NVIDIA SDK       0.500000   1.066231\n",
      "                Parboil          0.500000   1.336314\n",
      "                Polybench        0.444444   0.929101\n",
      "                Rodinia          0.516129   1.396762\n",
      "                SHOC             0.916667   2.109839\n",
      "\n",
      "--- Prediction results (summarized)\n",
      "                 Correct?   Speedup\n",
      "Platform                           \n",
      "AMD Tahiti 7970  0.721805  3.261375\n",
      "NVIDIA GTX 970   0.697744  1.352407\n"
     ]
    }
   ],
   "source": [
    "print('\\n--- Prediction results')\n",
    "print(result.groupby(['Platform', 'Benchmark Suite'])[['Correct?', 'Speedup']].mean())\n",
    "print('\\n--- Prediction results (summarized)')\n",
    "print(result.groupby(['Platform'])[['Correct?', 'Speedup']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "424ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pred_vals = [58.823529, 56.911765]\n",
    "static_pred_mean = 57.867647\n",
    "static_sp_vals = [1.0, 1.0]\n",
    "static_sp_mean = 1.0\n",
    "grewe_pred_vals = [73.382353, 72.941176]\n",
    "grewe_pred_mean = 73.161765\n",
    "grewe_sp_vals = [2.905822, 1.264801]\n",
    "grewe_sp_mean = 2.085312\n",
    "deeptune_pred_vals = [83.676471, 80.294118]\n",
    "deeptune_pred_mean = 81.985294\n",
    "deeptune_sp_vals = [2.998314, 1.088315]\n",
    "deeptune_sp_mean = 2.043315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d55b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model comparison: prediction accuracy\n",
      "\n",
      "                  Static mapping  Grewe et al.   DeepTune  Modernbert\n",
      "AMD Tahiti 7970       58.823529     73.382353  83.676471   72.180451\n",
      "NVIDIA GTX 970        56.911765     72.941176  80.294118   69.774436\n",
      "Average               57.867647     73.161765  81.985294   70.977444\n"
     ]
    }
   ],
   "source": [
    "# Model comparison: prediction accuracy\n",
    "print('\\n--- Model comparison: prediction accuracy')\n",
    "d = list()\n",
    "d.append(np.append(static_pred_vals, static_pred_mean))\n",
    "d.append(np.append(grewe_pred_vals, grewe_pred_mean))\n",
    "d.append(np.append(deeptune_pred_vals, deeptune_pred_mean))\n",
    "d.append(np.append(result.groupby(['Platform'])['Correct?'].mean().values * 100,\n",
    "                    result['Correct?'].mean() * 100))\n",
    "d = np.array(d).T\n",
    "print('\\n', pd.DataFrame(d, columns=['Static mapping', 'Grewe et al.', 'DeepTune', 'Modernbert'],\n",
    "                             index=['AMD Tahiti 7970', 'NVIDIA GTX 970', 'Average']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "491c90a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model comparison: speedups\n",
      "\n",
      "                  Static mapping  Grewe et al.  DeepTuneInst2Vec  Modernbert\n",
      "AMD Tahiti 7970             1.0      2.905822          2.998314    3.261375\n",
      "NVIDIA GTX 970              1.0      1.264801          1.088315    1.352407\n",
      "Average                     1.0      2.085312          2.043315    2.306891\n"
     ]
    }
   ],
   "source": [
    "# Model comparison: speedups\n",
    "print('\\n--- Model comparison: speedups')\n",
    "d = list()\n",
    "d.append(np.append(static_sp_vals, static_sp_mean))\n",
    "d.append(np.append(grewe_sp_vals, grewe_sp_mean))\n",
    "d.append(np.append(deeptune_sp_vals, deeptune_sp_mean))\n",
    "d.append(np.append(result.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                    result['Speedup'].mean()))\n",
    "d = np.array(d).T\n",
    "print('\\n', pd.DataFrame(d, columns=['Static mapping', 'Grewe et al.', 'DeepTuneInst2Vec', 'Modernbert'],\n",
    "                            index=['AMD Tahiti 7970', 'NVIDIA GTX 970', 'Average']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a71b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
