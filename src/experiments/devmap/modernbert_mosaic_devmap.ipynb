{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05cf6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/xucong24\")\n",
    "sys.path.append(\"/home/xucong24/ModernBERT\")\n",
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from Compiler.src.utils.system import read_ir_from_file\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Compiler.src.observation.inst2vec import Inst2vecEncoder\n",
    "from Compiler.src.utils.llvm import compile_c_to_llvm_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17df3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "import src.mosaic_bert as mosaic_bert_module\n",
    "from omegaconf import DictConfig\n",
    "from omegaconf import OmegaConf as om\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da18a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/xucong24/ModernBERT/yamls/defaults.yaml') as f:\n",
    "    default_cfg = om.load(f)\n",
    "\n",
    "with open('/home/xucong24/ModernBERT/yamls/main/mosaic-bert-base-uncased.yaml') as f:\n",
    "    yaml_cfg = om.load(f)\n",
    "\n",
    "cfg = om.merge(default_cfg, yaml_cfg)\n",
    "cfg = cast(DictConfig, cfg)  # for type checking\n",
    "cfg.model['pretrained_checkpoint'] = '/home/xucong24/ModernBERT/mosaic-bert-base-uncased/ckpt/latest-rank0.pt'\n",
    "cfg.model['pretrained_model_name'] = \"/home/xucong24/bert-base-uncased\"\n",
    "cfg.model['tokenizer_name'] = \"/home/xucong24/bert-base-uncased\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc595d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mosaic_bert', 'model_config': {'normalization': 'layernorm', 'hidden_act': 'gelu', 'num_attention_heads': 12, 'num_hidden_layers': 12, 'attention_probs_dropout_prob': 0.0, 'deterministic_fa2': False}, 'pretrained_model_name': '/home/xucong24/bert-base-uncased', 'tokenizer_name': '/home/xucong24/bert-base-uncased', 'pretrained_checkpoint': '/home/xucong24/ModernBERT/mosaic-bert-base-uncased/ckpt/latest-rank0.pt'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b013ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xucong24/ModernBERT/src/bert_layers/attention.py:89: UserWarning: Unable to import flash_attn; defaulting MosaicBERT attention implementation to vanilla PyTorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "/home/xucong24/ModernBERT/src/bert_layers/model.py:332: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pretrained_checkpoint)\n",
      "Found these missing keys in the checkpoint: bert.embeddings.word_embeddings.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.0.attention.self.Wqkv.weight, bert.encoder.layer.0.attention.self.Wqkv.bias, bert.encoder.layer.0.attention.output.dense.weight, bert.encoder.layer.0.attention.output.dense.bias, bert.encoder.layer.0.attention.output.LayerNorm.weight, bert.encoder.layer.0.attention.output.LayerNorm.bias, bert.encoder.layer.0.mlp.gated_layers.weight, bert.encoder.layer.0.mlp.wo.weight, bert.encoder.layer.0.mlp.wo.bias, bert.encoder.layer.0.mlp.layernorm.weight, bert.encoder.layer.0.mlp.layernorm.bias, bert.encoder.layer.1.attention.self.Wqkv.weight, bert.encoder.layer.1.attention.self.Wqkv.bias, bert.encoder.layer.1.attention.output.dense.weight, bert.encoder.layer.1.attention.output.dense.bias, bert.encoder.layer.1.attention.output.LayerNorm.weight, bert.encoder.layer.1.attention.output.LayerNorm.bias, bert.encoder.layer.1.mlp.gated_layers.weight, bert.encoder.layer.1.mlp.wo.weight, bert.encoder.layer.1.mlp.wo.bias, bert.encoder.layer.1.mlp.layernorm.weight, bert.encoder.layer.1.mlp.layernorm.bias, bert.encoder.layer.2.attention.self.Wqkv.weight, bert.encoder.layer.2.attention.self.Wqkv.bias, bert.encoder.layer.2.attention.output.dense.weight, bert.encoder.layer.2.attention.output.dense.bias, bert.encoder.layer.2.attention.output.LayerNorm.weight, bert.encoder.layer.2.attention.output.LayerNorm.bias, bert.encoder.layer.2.mlp.gated_layers.weight, bert.encoder.layer.2.mlp.wo.weight, bert.encoder.layer.2.mlp.wo.bias, bert.encoder.layer.2.mlp.layernorm.weight, bert.encoder.layer.2.mlp.layernorm.bias, bert.encoder.layer.3.attention.self.Wqkv.weight, bert.encoder.layer.3.attention.self.Wqkv.bias, bert.encoder.layer.3.attention.output.dense.weight, bert.encoder.layer.3.attention.output.dense.bias, bert.encoder.layer.3.attention.output.LayerNorm.weight, bert.encoder.layer.3.attention.output.LayerNorm.bias, bert.encoder.layer.3.mlp.gated_layers.weight, bert.encoder.layer.3.mlp.wo.weight, bert.encoder.layer.3.mlp.wo.bias, bert.encoder.layer.3.mlp.layernorm.weight, bert.encoder.layer.3.mlp.layernorm.bias, bert.encoder.layer.4.attention.self.Wqkv.weight, bert.encoder.layer.4.attention.self.Wqkv.bias, bert.encoder.layer.4.attention.output.dense.weight, bert.encoder.layer.4.attention.output.dense.bias, bert.encoder.layer.4.attention.output.LayerNorm.weight, bert.encoder.layer.4.attention.output.LayerNorm.bias, bert.encoder.layer.4.mlp.gated_layers.weight, bert.encoder.layer.4.mlp.wo.weight, bert.encoder.layer.4.mlp.wo.bias, bert.encoder.layer.4.mlp.layernorm.weight, bert.encoder.layer.4.mlp.layernorm.bias, bert.encoder.layer.5.attention.self.Wqkv.weight, bert.encoder.layer.5.attention.self.Wqkv.bias, bert.encoder.layer.5.attention.output.dense.weight, bert.encoder.layer.5.attention.output.dense.bias, bert.encoder.layer.5.attention.output.LayerNorm.weight, bert.encoder.layer.5.attention.output.LayerNorm.bias, bert.encoder.layer.5.mlp.gated_layers.weight, bert.encoder.layer.5.mlp.wo.weight, bert.encoder.layer.5.mlp.wo.bias, bert.encoder.layer.5.mlp.layernorm.weight, bert.encoder.layer.5.mlp.layernorm.bias, bert.encoder.layer.6.attention.self.Wqkv.weight, bert.encoder.layer.6.attention.self.Wqkv.bias, bert.encoder.layer.6.attention.output.dense.weight, bert.encoder.layer.6.attention.output.dense.bias, bert.encoder.layer.6.attention.output.LayerNorm.weight, bert.encoder.layer.6.attention.output.LayerNorm.bias, bert.encoder.layer.6.mlp.gated_layers.weight, bert.encoder.layer.6.mlp.wo.weight, bert.encoder.layer.6.mlp.wo.bias, bert.encoder.layer.6.mlp.layernorm.weight, bert.encoder.layer.6.mlp.layernorm.bias, bert.encoder.layer.7.attention.self.Wqkv.weight, bert.encoder.layer.7.attention.self.Wqkv.bias, bert.encoder.layer.7.attention.output.dense.weight, bert.encoder.layer.7.attention.output.dense.bias, bert.encoder.layer.7.attention.output.LayerNorm.weight, bert.encoder.layer.7.attention.output.LayerNorm.bias, bert.encoder.layer.7.mlp.gated_layers.weight, bert.encoder.layer.7.mlp.wo.weight, bert.encoder.layer.7.mlp.wo.bias, bert.encoder.layer.7.mlp.layernorm.weight, bert.encoder.layer.7.mlp.layernorm.bias, bert.encoder.layer.8.attention.self.Wqkv.weight, bert.encoder.layer.8.attention.self.Wqkv.bias, bert.encoder.layer.8.attention.output.dense.weight, bert.encoder.layer.8.attention.output.dense.bias, bert.encoder.layer.8.attention.output.LayerNorm.weight, bert.encoder.layer.8.attention.output.LayerNorm.bias, bert.encoder.layer.8.mlp.gated_layers.weight, bert.encoder.layer.8.mlp.wo.weight, bert.encoder.layer.8.mlp.wo.bias, bert.encoder.layer.8.mlp.layernorm.weight, bert.encoder.layer.8.mlp.layernorm.bias, bert.encoder.layer.9.attention.self.Wqkv.weight, bert.encoder.layer.9.attention.self.Wqkv.bias, bert.encoder.layer.9.attention.output.dense.weight, bert.encoder.layer.9.attention.output.dense.bias, bert.encoder.layer.9.attention.output.LayerNorm.weight, bert.encoder.layer.9.attention.output.LayerNorm.bias, bert.encoder.layer.9.mlp.gated_layers.weight, bert.encoder.layer.9.mlp.wo.weight, bert.encoder.layer.9.mlp.wo.bias, bert.encoder.layer.9.mlp.layernorm.weight, bert.encoder.layer.9.mlp.layernorm.bias, bert.encoder.layer.10.attention.self.Wqkv.weight, bert.encoder.layer.10.attention.self.Wqkv.bias, bert.encoder.layer.10.attention.output.dense.weight, bert.encoder.layer.10.attention.output.dense.bias, bert.encoder.layer.10.attention.output.LayerNorm.weight, bert.encoder.layer.10.attention.output.LayerNorm.bias, bert.encoder.layer.10.mlp.gated_layers.weight, bert.encoder.layer.10.mlp.wo.weight, bert.encoder.layer.10.mlp.wo.bias, bert.encoder.layer.10.mlp.layernorm.weight, bert.encoder.layer.10.mlp.layernorm.bias, bert.encoder.layer.11.attention.self.Wqkv.weight, bert.encoder.layer.11.attention.self.Wqkv.bias, bert.encoder.layer.11.attention.output.dense.weight, bert.encoder.layer.11.attention.output.dense.bias, bert.encoder.layer.11.attention.output.LayerNorm.weight, bert.encoder.layer.11.attention.output.LayerNorm.bias, bert.encoder.layer.11.mlp.gated_layers.weight, bert.encoder.layer.11.mlp.wo.weight, bert.encoder.layer.11.mlp.wo.bias, bert.encoder.layer.11.mlp.layernorm.weight, bert.encoder.layer.11.mlp.layernorm.bias, cls.predictions.transform.dense.weight, cls.predictions.transform.dense.bias, cls.predictions.transform.LayerNorm.weight, cls.predictions.transform.LayerNorm.bias, cls.predictions.decoder.weight, cls.predictions.decoder.bias\n",
      "Found these unexpected keys in the checkpoint: state, rng\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params=1.3740e+08\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing model...\")\n",
    "modern_bert_model = mosaic_bert_module.create_mosaic_bert_mlm(\n",
    "    pretrained_model_name=cfg.model.pretrained_model_name,\n",
    "    pretrained_checkpoint=cfg.model.get(\"pretrained_checkpoint\", None),\n",
    "    model_config=cfg.model.get(\"model_config\", None),\n",
    "    tokenizer_name=cfg.model.get(\"tokenizer_name\", None),\n",
    "    gradient_checkpointing=cfg.model.get(\"gradient_checkpointing\", None),\n",
    ")\n",
    "modern_bert_model = modern_bert_model.to(device='cuda')\n",
    "n_params = sum(p.numel() for p in modern_bert_model.parameters())\n",
    "print(f\"{n_params=:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "973f5349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceModel(\n",
       "  (model): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertAlibiEmbeddings(\n",
       "        (word_embeddings): Embedding(30528, 768, padding_idx=0)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertAlibiEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertAlibiLayer(\n",
       "            (attention): BertAlibiUnpadAttention(\n",
       "              (self): BertAlibiUnpadSelfAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (mlp): BertResidualGLU(\n",
       "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELU(approximate='none')\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30528, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a318874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xucong24/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594\n"
     ]
    }
   ],
   "source": [
    "!export HF_ENDPOINT=https://hf-mirror.com\n",
    "!huggingface-cli download --resume-download bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75c2764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/xucong24/bert-base-uncased\")\n",
    "inputs = tokenizer(\"Hello, this is a [MASK] example.\", return_tensors=\"pt\").to(device='cuda')\n",
    "outputs = modern_bert_model.model.bert(**inputs, output_hidden_states=True, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ab39fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "003260a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc3193ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceModel(\n",
       "  (model): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertAlibiEmbeddings(\n",
       "        (word_embeddings): Embedding(30528, 768, padding_idx=0)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertAlibiEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertAlibiLayer(\n",
       "            (attention): BertAlibiUnpadAttention(\n",
       "              (self): BertAlibiUnpadSelfAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (mlp): BertResidualGLU(\n",
       "              (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELU(approximate='none')\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30528, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern_bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0203be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/devmap_data'\n",
    "platform = 'all'\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "dense_layer_size = 32\n",
    "print_summary = False\n",
    "out_folder = 'output/modernbert_for_devmap'\n",
    "num_classes = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "platform2str = {\n",
    "    \"amd\": \"AMD Tahiti 7970\",\n",
    "    \"nvidia\": \"NVIDIA GTX 970\"\n",
    "}\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "assert platform in ['all', 'amd', 'nvidia'], \\\n",
    "    'Choose device among: all, amd, nvidia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1b8a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½DevMapæ•°æ®\n",
    "def load_data(data_path, platform):\n",
    "    # Load runtime data\n",
    "    df = pd.read_csv(data_path + \"/cgo17-{}.csv\".format(platform), index_col=0)\n",
    "    print('--- Read data from', data_path)\n",
    "\n",
    "    df[\"bench_data\"] = (\n",
    "        df.loc[df[\"dataset\"] != \"default\", \"benchmark\"]\n",
    "        + str(\"_\")\n",
    "        + df.loc[df[\"dataset\"] != \"default\", \"dataset\"]\n",
    "    )\n",
    "    df.loc[df[\"dataset\"] == \"default\", \"bench_data\"] = df.loc[\n",
    "        df[\"dataset\"] == \"default\", \"benchmark\"\n",
    "    ]\n",
    "\n",
    "    # llvmæ–‡ä»¶è·¯å¾„\n",
    "    df[\"bench_data_path\"] = data_path + '/kernels_ir/' + df[\"bench_data\"] + str(\".ll\")\n",
    "\n",
    "    # inst2vecç¼–ç \n",
    "    input_files = df[\"bench_data_path\"].values  \n",
    "    num_files = len(input_files)\n",
    "    print('--- Preparing to read', num_files, 'input files from folder', data_path + '/kernels_ir/')\n",
    "    seqs = list()\n",
    "\n",
    "    # éåŽ†æ–‡ä»¶ï¼Œè¯»å–ir\n",
    "    bad = []\n",
    "    for i in tqdm(range(num_files), desc='Encoding files'):\n",
    "        file = input_files[i]\n",
    "        if os.path.exists(file):\n",
    "            with open(file) as f:\n",
    "                ir = f.read()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # å‡è®¾ data æ˜¯è¾“å…¥å¼ é‡æˆ–å­—å…¸\n",
    "                inputs = tokenizer(ir, return_tensors=\"pt\", max_length=512).to(device='cuda')\n",
    "\n",
    "                outputs = modern_bert_model.model.bert(**inputs, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "                seqs.append(outputs[0].squeeze().to('cpu'))\n",
    "        else:\n",
    "            bad.append(i)\n",
    "    print(bad)\n",
    "            \n",
    "    # print('Number of benchmark  : {:>5}'.format(num_files))\n",
    "    # print('Mean sequence length : {:>5} (rounded down)'.format(math.floor(np.mean(seq_lengths))))\n",
    "    # print('Number of \\'UNK\\'      : {:>5}'.format(num_unks))\n",
    "    # print('Percentage of \\'UNK\\'  : {:>8.4} (% among all stmts)'.format((num_unks*100)/sum(seq_lengths)))\n",
    "\n",
    "    df = df.drop(bad)\n",
    "\n",
    "    # aux data\n",
    "    aux_in = np.array([\n",
    "        df[\"transfer\"].values,\n",
    "        df[\"wgsize\"].values,\n",
    "    ]).T\n",
    "    \n",
    "    # æ ‡ç­¾\n",
    "    label = np.array([1 if x == \"GPU\" else 0 for x in df[\"oracle\"].values])\n",
    "\n",
    "    return seqs, aux_in, label, df\n",
    "    \n",
    "class DevMapDataset(Dataset):\n",
    "    def __init__(self, sequences, aux_in, y):\n",
    "        super().__init__()\n",
    "        self.sequences = sequences\n",
    "        self.aux_in = aux_in\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        seqs = self.sequences[index]\n",
    "        aux = self.aux_in[index]\n",
    "        label = self.y[index]\n",
    "        return seqs, aux, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bc9fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ç½‘ç»œç»“æž„\n",
    "class DevMapLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_layers, dropout):\n",
    "        super(DevMapLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, embedding_dim, num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim * 2, num_classes)\n",
    "        \n",
    "        # self.fc_with_aux = nn.Linear(embedding_dim * 2 + 2, num_classes)\n",
    "    \n",
    "        # self.language_model_out = nn.Linear(embedding_dim, 2)\n",
    "        self.batch_norm = nn.BatchNorm1d(embedding_dim * 2 + 2)\n",
    "        # self.dense_1 = nn.Linear(embedding_dim * 2 + 2, 128)\n",
    "        # self.output = nn.Linear(128, 2)\n",
    "        self.fc2 = nn.Linear(embedding_dim * 2 + 2, 2)\n",
    "        \n",
    "    def forward(self, x, aux_input):\n",
    "\n",
    "        # x = self.embedding(x)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        lang_output = self.fc(x[:, -1, :])\n",
    "        # final_output = self.fc_with_aux(torch.cat((aux_input, x[:, -1, :]), dim=1))\n",
    "        \n",
    "        # out, _ = self.lstm_1(x)\n",
    "        # out, _ = self.lstm_2(out)\n",
    "        # lang_output = torch.sigmoid(self.language_model_out(out[:, -1, :]))\n",
    "        x_combined = torch.cat((aux_input, x[:, -1, :]), dim=1)\n",
    "        x_combined = self.batch_norm(x_combined)\n",
    "        # x_combined = torch.relu(self.dense_1(x_combined))\n",
    "        # final_output = torch.sigmoid(self.output(x_combined))\n",
    "        final_output = self.fc2(x_combined)\n",
    "        return final_output, lang_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ce9c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_suite_name(g: str) -> str:\n",
    "    c = g.split('-')\n",
    "    if c[0] == \"amd\" or c[0] == \"nvidia\":\n",
    "        return c[0].upper() + \" SDK\"\n",
    "    if c[0] == \"npb\" or c[0] == \"shoc\":\n",
    "        return c[0].upper()\n",
    "    elif c[0] == \"parboil\" or c[0] == \"polybench\" or c[0] == \"rodinia\":\n",
    "        return c[0].capitalize()\n",
    "    else:\n",
    "        raise LookupError\n",
    "\n",
    "def escape_benchmark_name(g: str) -> str:\n",
    "    c = g.split('-')\n",
    "    return escape_suite_name(c[0]).split()[0] + \".\" + c[-2]\n",
    "\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    pred_list, label_list =  [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, aux_input, labels = [b.to(device) for b in batch]\n",
    "            outputs, lang_outputs = model(sequences, aux_input)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            pred_list.extend(preds.tolist())\n",
    "            label_list.extend(batch[2].tolist())\n",
    "            \n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return accuracy, pred_list, label_list\n",
    "\n",
    "def train_model(model, train_loader, test_loader,  criterion, optimizer, num_epochs, model_path):\n",
    "    # æ¨¡åž‹è®­ç»ƒ\n",
    "    pre_eval_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        model.train()\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "        for idx, batch in enumerate(progress_bar):\n",
    "            sequences, aux_input, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, lang_outputs = model(sequences, aux_input)\n",
    "\n",
    "            # è®¡ç®—losså€¼ ç”±outputå’Œlang_outputsä¸Žlabelè®¡ç®—CrossEntropyLoss\n",
    "            loss = criterion(outputs, labels) + 0.2 * criterion(lang_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            progress_bar.set_postfix(loss=epoch_loss / (idx + 1))\n",
    "                    \n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "        eval_acc,_ , _ = eval_model(model, test_loader)\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}, loss: {epoch_loss:.4f}, train_acc: {accuracy:.4f}, eval_acc: {eval_acc:.4f}\")\n",
    "\n",
    "        if eval_acc > pre_eval_acc:\n",
    "            pre_eval_acc = eval_acc\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, weights_only=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3898e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Read data from data/devmap_data\n",
      "--- Preparing to read 680 input files from folder data/devmap_data/kernels_ir/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [00:41<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555, 556, 557, 558, 559, 560, 561, 562, 564, 566, 568, 569, 570, 571, 573]\n",
      "--- Cross validation step [ 0 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-0.pth , skipping...\n",
      "--- Evaluate Accuracy 0.5672\n",
      "--- Cross validation step [ 1 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-1.pth , skipping...\n",
      "--- Evaluate Accuracy 0.5821\n",
      "--- Cross validation step [ 2 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-2.pth , skipping...\n",
      "--- Evaluate Accuracy 0.5970\n",
      "--- Cross validation step [ 3 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-3.pth , skipping...\n",
      "--- Evaluate Accuracy 0.4030\n",
      "--- Cross validation step [ 4 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-4.pth , skipping...\n",
      "--- Evaluate Accuracy 0.4179\n",
      "--- Cross validation step [ 5 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-5.pth , skipping...\n",
      "--- Evaluate Accuracy 0.4091\n",
      "--- Cross validation step [ 6 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-6.pth , skipping...\n",
      "--- Evaluate Accuracy 0.5909\n",
      "--- Cross validation step [ 7 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-7.pth , skipping...\n",
      "--- Evaluate Accuracy 0.6061\n",
      "--- Cross validation step [ 8 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-8.pth , skipping...\n",
      "--- Evaluate Accuracy 0.5909\n",
      "--- Cross validation step [ 9 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-amd-9.pth , skipping...\n",
      "--- Evaluate Accuracy 0.4091\n",
      "--- Read data from data/devmap_data\n",
      "--- Preparing to read 680 input files from folder data/devmap_data/kernels_ir/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [00:24<00:00, 27.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555, 556, 557, 558, 559, 560, 561, 562, 564, 566, 568, 569, 570, 571, 573]\n",
      "--- Cross validation step [ 0 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-0.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7761\n",
      "--- Cross validation step [ 1 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-1.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7612\n",
      "--- Cross validation step [ 2 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-2.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7910\n",
      "--- Cross validation step [ 3 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-3.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8209\n",
      "--- Cross validation step [ 4 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-4.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7761\n",
      "--- Cross validation step [ 5 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-5.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8030\n",
      "--- Cross validation step [ 6 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-6.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8485\n",
      "--- Cross validation step [ 7 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-7.pth , skipping...\n",
      "--- Evaluate Accuracy 0.7121\n",
      "--- Cross validation step [ 8 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-8.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8182\n",
      "--- Cross validation step [ 9 / 10 ]\n",
      "Found trained model in output/modernbert_for_devmap/models/modern_bert_lstm-nvidia-9.pth , skipping...\n",
      "--- Evaluate Accuracy 0.8485\n"
     ]
    }
   ],
   "source": [
    "# platform_list = [\"amd\", \"nvidia\"]\n",
    "platform_list = [\"amd\", \"nvidia\"]\n",
    "\n",
    "data = []\n",
    "for i, platform in enumerate(platform_list):\n",
    "    # è¯»å–æ•°æ®é›†\n",
    "    sequences, aux_in, y, df = load_data(data_folder, platform)\n",
    "    aux_in_tensor = torch.tensor(aux_in, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "    # ä½¿ç”¨ F.normalize è¿›è¡Œ L2 å½’ä¸€åŒ–\n",
    "    # embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    # embedding_matrix_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=204)\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(sequences, y)):\n",
    "        print('--- Cross validation step [', j, '/ 10 ]')\n",
    "\n",
    "        model_basename = 'modern_bert_lstm'\n",
    "        model_path = os.path.join(out_folder, f\"models/{model_basename}-{platform}-{j}.pth\")\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        log_dir = os.path.join(out_folder, \"logs\")\n",
    "\n",
    "        # è¯»å–æ•°æ®é›†\n",
    "        train_data = DevMapDataset([sequences[i] for i in train_index], aux_in_tensor[train_index], y_tensor[train_index])\n",
    "        test_data = DevMapDataset([sequences[i] for i in test_index], aux_in_tensor[test_index], y_tensor[test_index])\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            # åˆ›å»ºæ¨¡åž‹\n",
    "            model = DevMapLSTM(768, 3, 0.5).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "            print('--- Training model... ')\n",
    "            train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, model_path)\n",
    "            \n",
    "        else:\n",
    "            # è¯»å–æ¨¡åž‹æƒé‡æ–‡ä»¶\n",
    "            model = DevMapLSTM(768, 3, 0.5)\n",
    "            model.load_state_dict(torch.load(model_path, weights_only=False))\n",
    "            model = model.to(device)\n",
    "            print(\"Found trained model in\", model_path, \", skipping...\")\n",
    "            \n",
    "        # æ¨¡åž‹é¢„æµ‹\n",
    "        eval_acc, pred_list, label_list = eval_model(model, test_loader)\n",
    "        print(f'--- Evaluate Accuracy {eval_acc:.4f}')\n",
    "        benchmarks = df['benchmark'].values[test_index]\n",
    "        correct = np.array(pred_list) == np.array(label_list)\n",
    "        zero_r_dev = \"runtime_cpu\" if platform == \"amd\" else \"runtime_gpu\"\n",
    "        zer_r_runtimes = df[zero_r_dev].values[test_index]\n",
    "        runtimes = df[['runtime_cpu', 'runtime_gpu']].values[test_index]\n",
    "        p_runtimes = [r[p_] for p_, r in zip(np.array(pred_list, dtype=int), runtimes)]\n",
    "        p_speedup = zer_r_runtimes / p_runtimes\n",
    "\n",
    "        assert len(benchmarks) == len(label_list) == len(correct) == len(pred_list) == len(p_speedup)\n",
    "\n",
    "        for benchmark_, o_, p_, correct_, p_speedup_ in zip(benchmarks, label_list, pred_list, correct, p_speedup):\n",
    "            data.append({\n",
    "                \"Model\": model_basename,\n",
    "                \"Platform\": platform2str[platform],\n",
    "                'Benchmark': escape_benchmark_name(benchmark_),\n",
    "                'Benchmark Suite': escape_suite_name(benchmark_),\n",
    "                \"Oracle Mapping\": int(o_),\n",
    "                \"Predicted Mapping\": int(p_),\n",
    "                \"Correct?\": bool(correct_),\n",
    "                \"Speedup\": float(p_speedup_),\n",
    "            })\n",
    "            \n",
    "result =  pd.DataFrame(\n",
    "    data, index=range(1, len(data) + 1), columns=[\n",
    "        \"Model\",\n",
    "        \"Platform\",\n",
    "        \"Benchmark\",\n",
    "        \"Benchmark Suite\",\n",
    "        \"Oracle Mapping\",\n",
    "        \"Predicted Mapping\",\n",
    "        \"Correct?\",\n",
    "        \"Speedup\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c455e07d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction results\n",
      "                                 Correct?   Speedup\n",
      "Platform        Benchmark Suite                    \n",
      "AMD Tahiti 7970 AMD SDK          0.625000  1.038627\n",
      "                NPB              0.519924  1.661979\n",
      "                NVIDIA SDK       0.583333  2.367625\n",
      "                Parboil          0.250000  0.905773\n",
      "                Polybench        0.444444  2.988316\n",
      "                Rodinia          0.516129  1.159666\n",
      "                SHOC             0.500000  1.337267\n",
      "NVIDIA GTX 970  AMD SDK          0.250000  0.534343\n",
      "                NPB              0.851992  1.381025\n",
      "                NVIDIA SDK       0.833333  1.195673\n",
      "                Parboil          0.750000  1.330145\n",
      "                Polybench        0.555556  0.958344\n",
      "                Rodinia          0.548387  1.303582\n",
      "                SHOC             0.645833  1.672062\n",
      "\n",
      "--- Prediction results (summarized)\n",
      "                 Correct?   Speedup\n",
      "Platform                           \n",
      "AMD Tahiti 7970  0.517293  1.662164\n",
      "NVIDIA GTX 970   0.795489  1.357239\n"
     ]
    }
   ],
   "source": [
    "print('\\n--- Prediction results')\n",
    "print(result.groupby(['Platform', 'Benchmark Suite'])[['Correct?', 'Speedup']].mean())\n",
    "print('\\n--- Prediction results (summarized)')\n",
    "print(result.groupby(['Platform'])[['Correct?', 'Speedup']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "424ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pred_vals = [58.823529, 56.911765]\n",
    "static_pred_mean = 57.867647\n",
    "static_sp_vals = [1.0, 1.0]\n",
    "static_sp_mean = 1.0\n",
    "grewe_pred_vals = [73.382353, 72.941176]\n",
    "grewe_pred_mean = 73.161765\n",
    "grewe_sp_vals = [2.905822, 1.264801]\n",
    "grewe_sp_mean = 2.085312\n",
    "deeptune_pred_vals = [77.428999, 77.414051]\n",
    "deeptune_pred_mean = 77.421525\n",
    "deeptune_sp_vals = [2.998314, 1.088315]\n",
    "deeptune_sp_mean = 2.043315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d55b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model comparison: prediction accuracy\n",
      "\n",
      "                  Static mapping  Grewe et al.  DeepTuneInst2Vec  Modernbert\n",
      "AMD Tahiti 7970       58.823529     73.382353         77.428999   51.729323\n",
      "NVIDIA GTX 970        56.911765     72.941176         77.414051   79.548872\n",
      "Average               57.867647     73.161765         77.421525   65.639098\n"
     ]
    }
   ],
   "source": [
    "# Model comparison: prediction accuracy\n",
    "print('\\n--- Model comparison: prediction accuracy')\n",
    "d = list()\n",
    "d.append(np.append(static_pred_vals, static_pred_mean))\n",
    "d.append(np.append(grewe_pred_vals, grewe_pred_mean))\n",
    "d.append(np.append(deeptune_pred_vals, deeptune_pred_mean))\n",
    "d.append(np.append(result.groupby(['Platform'])['Correct?'].mean().values * 100,\n",
    "                    result['Correct?'].mean() * 100))\n",
    "d = np.array(d).T\n",
    "print('\\n', pd.DataFrame(d, columns=['Static mapping', 'Grewe et al.', 'DeepTuneInst2Vec', 'Modernbert'],\n",
    "                             index=['AMD Tahiti 7970', 'NVIDIA GTX 970', 'Average']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "491c90a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model comparison: speedups\n",
      "\n",
      "                  Static mapping  Grewe et al.  DeepTuneInst2Vec  Modernbert\n",
      "AMD Tahiti 7970             1.0      2.905822          2.998314    1.662164\n",
      "NVIDIA GTX 970              1.0      1.264801          1.088315    1.357239\n",
      "Average                     1.0      2.085312          2.043315    1.509701\n"
     ]
    }
   ],
   "source": [
    "# Model comparison: speedups\n",
    "print('\\n--- Model comparison: speedups')\n",
    "d = list()\n",
    "d.append(np.append(static_sp_vals, static_sp_mean))\n",
    "d.append(np.append(grewe_sp_vals, grewe_sp_mean))\n",
    "d.append(np.append(deeptune_sp_vals, deeptune_sp_mean))\n",
    "d.append(np.append(result.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                    result['Speedup'].mean()))\n",
    "d = np.array(d).T\n",
    "print('\\n', pd.DataFrame(d, columns=['Static mapping', 'Grewe et al.', 'DeepTuneInst2Vec', 'Modernbert'],\n",
    "                            index=['AMD Tahiti 7970', 'NVIDIA GTX 970', 'Average']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a71b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
