【本周工作进展汇报】

1. 模型推理问题修复
   - 发现并解决了模型生成时出现重复bos符号的问题
   - 问题排查过程：在模型训练后测试generate功能时，发现生成的序列开头总是带着两个bos符号，影响了输出质量。经过仔细排查，发现是encoder-decoder训练时forward函数会将label右移并添加start_token，而OptiSeqTokenizer默认也会添加bos符号，两者叠加导致了重复
   - 根本原因：训练时tokenizer默认添加bos，导致和训练逻辑冲突（start_token和bos_token实际上是同一个）
   - 解决方案：给OptiSeqTokenizer添加了add_bos参数，可以灵活控制是否添加bos符号，这样就能避免重复添加的问题
   - 修复后模型生成正常，输出序列格式正确

2. 模型特征融合实验 
   - 新增了concat特征融合方式，用于将autophase特征更好地融入到模型中
   - 实验设计：对比了三种方案进行训练和评估
     1) 不添加autophase特征的baseline模型
     2) add融合方式（特征相加）
     3) concat融合方式（特征拼接）
   - 训练结果：在llvm-ir数据集上分别训练了20个epoch，从测试集loss来看，concat方式的效果略微优于前两种方式，说明特征拼接能保留更多信息
   - 模型结构：这里我绘制了下concat的模型结构图，可以更直观地看到特征是如何融合的
   - 下一步计划：后续会在compiler_gym上通过强化学习进一步验证实际优化效果，看看在真实编译优化场景下哪种方式表现更好

3. 强化学习准备
   - 算法学习：正在深入学习PPO（Proximal Policy Optimization）算法的实现原理和细节，这是目前比较主流的强化学习算法
   - 库评估：在调研现有的强化学习库（比如tcl等），看能否直接用来做后续的训练，这样可以节省开发时间
   - 框架搭建：正在搭建强化学习训练框架，包括环境封装、奖励函数设计、策略网络等核心组件，预计本周完成基础框架
   - 后续将基于compiler_gym环境进行强化学习训练，让模型在实际编译优化任务中学习更好的pass序列